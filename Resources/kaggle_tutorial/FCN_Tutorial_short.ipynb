{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Short Version of Caffe Net\n",
    "## for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dicom, lmdb, cv2, re, sys\n",
    "import os, fnmatch, shutil, subprocess\n",
    "from IPython.utils import io\n",
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "import caffe\n",
    "warnings.filterwarnings('ignore') # we ignore a RuntimeWarning produced from dividing by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zijia/caffe_FCN/python/caffe/__init__.pyc\n"
     ]
    }
   ],
   "source": [
    "print caffe.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_gpu() # or caffe.set_mode_cpu() for machines without a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MEAN_VALUE = 77\n",
    "THRESH = 0.5\n",
    "\n",
    "def calc_all_areas(images):\n",
    "    (num_images, times, _, _) = images.shape\n",
    "    \n",
    "    all_masks = [{} for i in range(times)]\n",
    "    all_areas = [{} for i in range(times)]\n",
    "    for i in range(times):\n",
    "        for j in range(num_images):\n",
    "            # print 'Calculating area for time %d and slice %d...' % (i, j)\n",
    "            img = images[j][i]\n",
    "            in_ = np.expand_dims(img, axis=0)\n",
    "            in_ -= np.array([MEAN_VALUE])\n",
    "            net.blobs['data'].reshape(1, *in_.shape)\n",
    "            net.blobs['data'].data[...] = in_\n",
    "            net.forward()\n",
    "            prob = net.blobs['prob'].data\n",
    "            obj = prob[0][1]\n",
    "            preds = np.where(obj > THRESH, 1, 0)\n",
    "            all_masks[i][j] = preds\n",
    "            all_areas[i][j] = np.count_nonzero(preds)\n",
    "\n",
    "    return all_masks, all_areas\n",
    "\n",
    "def calc_total_volume(areas, area_multiplier, dist):\n",
    "    slices = np.array(sorted(areas.keys()))\n",
    "    modified = [areas[i] * area_multiplier for i in slices]\n",
    "    vol = 0\n",
    "    for i in slices[:-1]:\n",
    "        a, b = modified[i], modified[i+1]\n",
    "        subvol = (dist/3.0) * (a + np.sqrt(a*b) + b)\n",
    "        vol += subvol / 1000.0  # conversion to mL\n",
    "    return vol\n",
    "\n",
    "def segment_dataset(dataset):\n",
    "    # shape: num slices, num snapshots, rows, columns\n",
    "    print 'Calculating areas...'\n",
    "    all_masks, all_areas = calc_all_areas(dataset.images)\n",
    "    print 'Calculating volumes...'\n",
    "    area_totals = [calc_total_volume(a, dataset.area_multiplier, dataset.dist)\n",
    "                   for a in all_areas]\n",
    "    print 'Calculating EF...'\n",
    "    edv = max(area_totals)\n",
    "    esv = min(area_totals)\n",
    "    ef = (edv - esv) / edv\n",
    "    print 'Done, EF is {:0.4f}'.format(ef)\n",
    "    \n",
    "    dataset.edv = edv\n",
    "    dataset.esv = esv\n",
    "    dataset.ef = ef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, now that we have defined our helper functions, we can succinctly express the process of loading, segmenting, and scoring the dataset in the following code snippet to produce a file in comma-separated values for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 4s, sys: 3min 42s, total: 21min 46s\n",
      "Wall time: 25min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# We capture all standard output from IPython so it does not flood the interface.\n",
    "with io.capture_output() as captured:\n",
    "    # edit this so it matches where you download the DSB data\n",
    "    DATA_PATH = '/home/jinjing/Desktop/dataset/'\n",
    "\n",
    "    caffe.set_mode_gpu()\n",
    "    net = caffe.Net('fcn_deploy.prototxt', './model_logs/fcn_iter_15000.caffemodel', caffe.TEST)\n",
    "\n",
    "    train_dir = os.path.join(DATA_PATH, 'train')\n",
    "    studies = next(os.walk(train_dir))[1]\n",
    "\n",
    "    labels = np.loadtxt(os.path.join(DATA_PATH, 'train.csv'), delimiter=',',\n",
    "                        skiprows=1)\n",
    "\n",
    "    label_map = {}\n",
    "    for l in labels:\n",
    "        label_map[l[0]] = (l[2], l[1])\n",
    "\n",
    "    if os.path.exists('output'):\n",
    "        shutil.rmtree('output')\n",
    "    os.mkdir('output')\n",
    "\n",
    "    accuracy_csv = open('accuracy.csv', 'w')\n",
    "\n",
    "    for s in studies:\n",
    "        dset = Dataset(os.path.join(train_dir, s), s)\n",
    "        print 'Processing dataset %s...' % dset.name\n",
    "        try:\n",
    "            dset.load()\n",
    "            segment_dataset(dset)\n",
    "            (edv, esv) = label_map[int(dset.name)]\n",
    "            accuracy_csv.write('%s,%f,%f,%f,%f\\n' %\n",
    "                               (dset.name, edv, esv, dset.edv, dset.esv))\n",
    "        except Exception as e:\n",
    "            print '***ERROR***: Exception %s thrown by dataset %s' % (str(e), dset.name)\n",
    "\n",
    "    accuracy_csv.close()\n",
    "\n",
    "# We redirect the captured stdout to a log file on disk.\n",
    "# This log file is very useful in identifying potential dataset irregularities that throw errors/exceptions in the code.\n",
    "with open('logs.txt', 'w') as f:\n",
    "    f.write(captured.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes about 75 minutes to apply the FCN model on all DICOM images in the DSB training set, extract LV contours, compute EDV/ESV volumes, and calculate EF on a MacBook Pro using NVIDIA GeForce GT 750M with 2GB of dedicated GPU memory. We can reduce the processing time if we enable the code sections above to perform *batch* processing. The code is currently configured to call Caffe and transfer data between CPU and GPU for *each* image. While data processing on the GPU is extremely fast, the constant data communication overhead negates some of the speed benefits. Batch processing can be done, for example, by batching all DICOM images belonging to a SAX study in a big NumPy stack and calling Caffe via `net.forward_all()` to load the NumPy stack into the GPU for batch processing. Although enabling batch processing will likely complicate the code, keep in mind that speed and efficiency will become critical as your model grows in complexity and size; it can be discouraging to try many experiments if an experiment takes a few hours to complete. Finally, remember to check the file `logs.txt`. This code is equipped to handle exceptions and errors associated with the DSB dataset. Upon inspection of the logs, we discover that a good amount of examples in the DSB training set contain irregularities. It is also likely that the validation and testing sets contain similar irregularities. The reader should do their best to handle these situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 produces the file `accuracy.csv`, which consists of five columns with headers: IDs, actual EDV, actual ESV, predicted EDV, predicted ESV. The code below calculates actual and predicted EF from the EDV and ESV fields, through the simple relation `EF = (EDV - ESV) / EDV`, and computes some commonly used error metrics for the assessment of our model's predictive performance. We ignore (filter out) instances where the FCN model predicts zero values for EDV because we cannot derive a predicted EF value. I recommend the following strategies to remedy the shortcoming:\n",
    "* Impute the values for EDV, ESV, or both in instances where there are no predictions through interpolation: sample mean/median or through sophisticated polynomial interpolation using Python `scipy.interpolate`.\n",
    "* Continue improving the FCN model via tweaking and refinement. The idea is that as the model becomes more accurate in its capability to segment LV contours across the Sunnybrook and DSB datasets, then it is able to predict EDV/ESV/EF values with more precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error (MAE) for predicted EF: 0.1695\n",
      "Root mean square error (RMSE) for predicted EF: 0.2151\n",
      "Standard deviation of actual EF: 0.1080\n",
      "Median value of actual EF: 0.6027\n"
     ]
    }
   ],
   "source": [
    "# calculate some error metrics to evaluate actual vs. predicted EF values obtained from FCN model\n",
    "data = np.transpose(np.loadtxt('accuracy.csv', delimiter=',')).astype('float')\n",
    "ids, actual_edv, actual_esv, predicted_edv, predicted_esv = data\n",
    "actual_ef = (actual_edv - actual_esv) / actual_edv\n",
    "actual_ef_std = np.std(actual_ef)\n",
    "actual_ef_median = np.median(actual_ef)\n",
    "predicted_ef = (predicted_edv - predicted_esv) / predicted_edv # potential of dividing by zero, where there is no predicted EDV value\n",
    "nan_idx = np.isnan(predicted_ef)\n",
    "actual_ef = actual_ef[~nan_idx]\n",
    "predicted_ef = predicted_ef[~nan_idx]\n",
    "MAE = np.mean(np.abs(actual_ef - predicted_ef))\n",
    "RMSE = np.sqrt(np.mean((actual_ef - predicted_ef)**2))\n",
    "print 'Mean absolute error (MAE) for predicted EF: {:0.4f}'.format(MAE)\n",
    "print 'Root mean square error (RMSE) for predicted EF: {:0.4f}'.format(RMSE)\n",
    "print 'Standard deviation of actual EF: {:0.4f}'.format(actual_ef_std)\n",
    "print 'Median value of actual EF: {:0.4f}'.format(actual_ef_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FCN model achieves a mean absolute error (MAE) of `0.1796` and a root mean square error (RMSE) of `0.2265` for predicting ejection fraction (EF) on the DSB training set. In order to establish a frame of reference for these error values, we compare them to errors obtained from uniform random EF predictions (MAE = 0.2623, RMSE = 0.3128). However, if instead we use the median value of actual EF as reference predictions (MAE = 0.0776, RMSE = 0.1096), then our FCN results do not seem great in comparison. Let us not give up in despair. This is not a bad result considering the FCN model has not seen one image from the DSB dataset. The good news here is that our *baseline* FCN model is just the tip of the iceberg; there are many ways one can significantly improve upon this initial result (hint hint), and this is where the excitement of the competition ultimately lies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some ideas for improvement\n",
    "That's all, folks! This tutorial has shown how one can apply a fully convolutional network to segment the left ventricle from MRI images and to compute important metrics critical for diagnosing cardiovascular health. However, there is still a tremendous amount of work left to be done. Below are some ideas to consider for improving the performance of our baseline fully convolutional network:\n",
    "\n",
    "1. Expand the size of the network by increasing depth, width, or both.\n",
    "2. Explore different learning rates, weight initialization strategies, solver types, kernel sizes, strides, dropout ratio, and other network hyper-parameters that could positively impact its learning performance.\n",
    "3. Implement alternative pooling layers, such as cyclic pooling or fractional max-pooling.\n",
    "4. Investigate whether or not other non-linearities help improve performance, such as leaky ReLUs, parametric ReLUs, or exponential linear units (ELUs).\n",
    "5. Combine multiple models through bagging, boosting, stacking, and other methods in ensemble learning to improve predictive performance.\n",
    "6. Try out your own novel idea; this is the perfect platform to do so.\n",
    "\n",
    "I hope you find this tutorial useful in getting you started in the competition. Good luck on your quest to win a prize. I am anxious to see what innovative ideas will come out of this year's Data Science Bowl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "The following references on Caffe may be useful:\n",
    "\n",
    "* Deconvolution layer - https://github.com/BVLC/caffe/pull/1615\n",
    "* Crop layer - https://github.com/BVLC/caffe/pull/1976\n",
    "* Bilinear upsampling - https://github.com/BVLC/caffe/pull/2213\n",
    "* On-the-fly net resizing - https://github.com/BVLC/caffe/pull/594\n",
    "* Main Caffe tutorial - http://caffe.berkeleyvision.org/tutorial/\n",
    "* Caffe examples - http://caffe.berkeleyvision.org/\n",
    "* Caffe net specification - https://github.com/BVLC/caffe/blob/master/src/caffe/proto/caffe.proto\n",
    "* Caffe users group - https://groups.google.com/forum/#!forum/caffe-users\n",
    "* Caffe GitHub page - https://github.com/BVLC/caffe\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
