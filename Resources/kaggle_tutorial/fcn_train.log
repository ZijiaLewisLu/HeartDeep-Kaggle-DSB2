I0607 17:39:39.061506 13702 caffe.cpp:183] Using GPUs 0
I0607 17:39:41.092946 13702 solver.cpp:54] Initializing solver from parameters: 
train_net: "fcn_train.prototxt"
test_net: "fcn_test.prototxt"
test_iter: 26
test_interval: 200
base_lr: 0.01
display: 200
max_iter: 15000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 2500
snapshot_prefix: "./model_logs/fcn"
device_id: 0
random_seed: 5
test_initialization: true
average_loss: 200
stepvalue: 10000
I0607 17:39:41.093016 13702 solver.cpp:86] Creating training net from train_net file: fcn_train.prototxt
I0607 17:39:41.094027 13702 net.cpp:50] Initializing net from parameters: 
name: "FCN"
force_backward: true
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  transform_param {
    mirror: false
    crop_size: 0
    mean_value: 77
  }
  data_param {
    source: "train_images_lmdb/"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "label"
  type: "Data"
  top: "label"
  data_param {
    source: "train_labels_lmdb/"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 100
    pad: 50
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 200
    pad: 0
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 300
    pad: 0
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 300
    pad: 0
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "drop"
  type: "Dropout"
  bottom: "conv4"
  top: "conv4"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "score_classes"
  type: "Convolution"
  bottom: "conv4"
  top: "score_classes"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "score_classes"
  top: "upscore"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    bias_term: true
    pad: 8
    kernel_size: 31
    stride: 16
    weight_filler {
      type: "bilinear"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "score"
  type: "Crop"
  bottom: "upscore"
  bottom: "data"
  top: "score"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
  loss_param {
    normalize: true
  }
}
I0607 17:39:41.094218 13702 layer_factory.hpp:76] Creating layer data
I0607 17:39:41.094344 13702 net.cpp:111] Creating Layer data
I0607 17:39:41.094370 13702 net.cpp:434] data -> data
I0607 17:39:41.095181 13712 db_lmdb.cpp:22] Opened lmdb train_images_lmdb/
I0607 17:39:41.095569 13702 data_layer.cpp:44] output data size: 1,1,256,256
I0607 17:39:41.105348 13702 net.cpp:156] Setting up data
I0607 17:39:41.105407 13702 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0607 17:39:41.105428 13702 layer_factory.hpp:76] Creating layer data_data_0_split
I0607 17:39:41.105453 13702 net.cpp:111] Creating Layer data_data_0_split
I0607 17:39:41.105469 13702 net.cpp:478] data_data_0_split <- data
I0607 17:39:41.105489 13702 net.cpp:434] data_data_0_split -> data_data_0_split_0
I0607 17:39:41.105511 13702 net.cpp:434] data_data_0_split -> data_data_0_split_1
I0607 17:39:41.105537 13702 net.cpp:156] Setting up data_data_0_split
I0607 17:39:41.105554 13702 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0607 17:39:41.105568 13702 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0607 17:39:41.105581 13702 layer_factory.hpp:76] Creating layer label
I0607 17:39:41.105666 13702 net.cpp:111] Creating Layer label
I0607 17:39:41.105685 13702 net.cpp:434] label -> label
I0607 17:39:41.106601 13714 db_lmdb.cpp:22] Opened lmdb train_labels_lmdb/
I0607 17:39:41.106719 13702 data_layer.cpp:44] output data size: 1,1,256,256
I0607 17:39:41.107815 13702 net.cpp:156] Setting up label
I0607 17:39:41.107841 13702 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0607 17:39:41.107856 13702 layer_factory.hpp:76] Creating layer conv1
I0607 17:39:41.107880 13702 net.cpp:111] Creating Layer conv1
I0607 17:39:41.107893 13702 net.cpp:478] conv1 <- data_data_0_split_0
I0607 17:39:41.107920 13702 net.cpp:434] conv1 -> conv1
I0607 17:39:41.109063 13702 net.cpp:156] Setting up conv1
I0607 17:39:41.109086 13702 net.cpp:164] Top shape: 1 100 176 176 (3097600)
I0607 17:39:41.109117 13702 layer_factory.hpp:76] Creating layer relu1
I0607 17:39:41.109138 13702 net.cpp:111] Creating Layer relu1
I0607 17:39:41.109149 13702 net.cpp:478] relu1 <- conv1
I0607 17:39:41.109165 13702 net.cpp:420] relu1 -> conv1 (in-place)
I0607 17:39:41.109184 13702 net.cpp:156] Setting up relu1
I0607 17:39:41.109199 13702 net.cpp:164] Top shape: 1 100 176 176 (3097600)
I0607 17:39:41.109210 13702 layer_factory.hpp:76] Creating layer pool1
I0607 17:39:41.109225 13702 net.cpp:111] Creating Layer pool1
I0607 17:39:41.109236 13702 net.cpp:478] pool1 <- conv1
I0607 17:39:41.109248 13702 net.cpp:434] pool1 -> pool1
I0607 17:39:41.109282 13702 net.cpp:156] Setting up pool1
I0607 17:39:41.109298 13702 net.cpp:164] Top shape: 1 100 88 88 (774400)
I0607 17:39:41.109309 13702 layer_factory.hpp:76] Creating layer conv2
I0607 17:39:41.109333 13702 net.cpp:111] Creating Layer conv2
I0607 17:39:41.109346 13702 net.cpp:478] conv2 <- pool1
I0607 17:39:41.109361 13702 net.cpp:434] conv2 -> conv2
I0607 17:39:41.127701 13702 net.cpp:156] Setting up conv2
I0607 17:39:41.127748 13702 net.cpp:164] Top shape: 1 200 42 42 (352800)
I0607 17:39:41.127774 13702 layer_factory.hpp:76] Creating layer relu2
I0607 17:39:41.127791 13702 net.cpp:111] Creating Layer relu2
I0607 17:39:41.127802 13702 net.cpp:478] relu2 <- conv2
I0607 17:39:41.127818 13702 net.cpp:420] relu2 -> conv2 (in-place)
I0607 17:39:41.127836 13702 net.cpp:156] Setting up relu2
I0607 17:39:41.127848 13702 net.cpp:164] Top shape: 1 200 42 42 (352800)
I0607 17:39:41.127858 13702 layer_factory.hpp:76] Creating layer pool2
I0607 17:39:41.127873 13702 net.cpp:111] Creating Layer pool2
I0607 17:39:41.127883 13702 net.cpp:478] pool2 <- conv2
I0607 17:39:41.127905 13702 net.cpp:434] pool2 -> pool2
I0607 17:39:41.127934 13702 net.cpp:156] Setting up pool2
I0607 17:39:41.127948 13702 net.cpp:164] Top shape: 1 200 21 21 (88200)
I0607 17:39:41.127959 13702 layer_factory.hpp:76] Creating layer conv3
I0607 17:39:41.127976 13702 net.cpp:111] Creating Layer conv3
I0607 17:39:41.127986 13702 net.cpp:478] conv3 <- pool2
I0607 17:39:41.127998 13702 net.cpp:434] conv3 -> conv3
I0607 17:39:41.147974 13702 net.cpp:156] Setting up conv3
I0607 17:39:41.148015 13702 net.cpp:164] Top shape: 1 300 19 19 (108300)
I0607 17:39:41.148046 13702 layer_factory.hpp:76] Creating layer relu3
I0607 17:39:41.148067 13702 net.cpp:111] Creating Layer relu3
I0607 17:39:41.148082 13702 net.cpp:478] relu3 <- conv3
I0607 17:39:41.148102 13702 net.cpp:420] relu3 -> conv3 (in-place)
I0607 17:39:41.148123 13702 net.cpp:156] Setting up relu3
I0607 17:39:41.148138 13702 net.cpp:164] Top shape: 1 300 19 19 (108300)
I0607 17:39:41.148149 13702 layer_factory.hpp:76] Creating layer conv4
I0607 17:39:41.148165 13702 net.cpp:111] Creating Layer conv4
I0607 17:39:41.148177 13702 net.cpp:478] conv4 <- conv3
I0607 17:39:41.148193 13702 net.cpp:434] conv4 -> conv4
I0607 17:39:41.172101 13702 net.cpp:156] Setting up conv4
I0607 17:39:41.172140 13702 net.cpp:164] Top shape: 1 300 17 17 (86700)
I0607 17:39:41.172153 13702 layer_factory.hpp:76] Creating layer relu4
I0607 17:39:41.172165 13702 net.cpp:111] Creating Layer relu4
I0607 17:39:41.172173 13702 net.cpp:478] relu4 <- conv4
I0607 17:39:41.172181 13702 net.cpp:420] relu4 -> conv4 (in-place)
I0607 17:39:41.172193 13702 net.cpp:156] Setting up relu4
I0607 17:39:41.172199 13702 net.cpp:164] Top shape: 1 300 17 17 (86700)
I0607 17:39:41.172204 13702 layer_factory.hpp:76] Creating layer drop
I0607 17:39:41.172216 13702 net.cpp:111] Creating Layer drop
I0607 17:39:41.172222 13702 net.cpp:478] drop <- conv4
I0607 17:39:41.172231 13702 net.cpp:420] drop -> conv4 (in-place)
I0607 17:39:41.172250 13702 net.cpp:156] Setting up drop
I0607 17:39:41.172256 13702 net.cpp:164] Top shape: 1 300 17 17 (86700)
I0607 17:39:41.172262 13702 layer_factory.hpp:76] Creating layer score_classes
I0607 17:39:41.172271 13702 net.cpp:111] Creating Layer score_classes
I0607 17:39:41.172277 13702 net.cpp:478] score_classes <- conv4
I0607 17:39:41.172286 13702 net.cpp:434] score_classes -> score_classes
I0607 17:39:41.172356 13702 net.cpp:156] Setting up score_classes
I0607 17:39:41.172369 13702 net.cpp:164] Top shape: 1 2 17 17 (578)
I0607 17:39:41.172381 13702 layer_factory.hpp:76] Creating layer upscore
I0607 17:39:41.172394 13702 net.cpp:111] Creating Layer upscore
I0607 17:39:41.172399 13702 net.cpp:478] upscore <- score_classes
I0607 17:39:41.172407 13702 net.cpp:434] upscore -> upscore
I0607 17:39:41.173002 13702 net.cpp:156] Setting up upscore
I0607 17:39:41.173015 13702 net.cpp:164] Top shape: 1 2 271 271 (146882)
I0607 17:39:41.173024 13702 layer_factory.hpp:76] Creating layer score
I0607 17:39:41.173037 13702 net.cpp:111] Creating Layer score
I0607 17:39:41.173043 13702 net.cpp:478] score <- upscore
I0607 17:39:41.173049 13702 net.cpp:478] score <- data_data_0_split_1
I0607 17:39:41.173056 13702 net.cpp:434] score -> score
I0607 17:39:41.173101 13702 net.cpp:156] Setting up score
I0607 17:39:41.173110 13702 net.cpp:164] Top shape: 1 2 256 256 (131072)
I0607 17:39:41.173117 13702 layer_factory.hpp:76] Creating layer loss
I0607 17:39:41.173126 13702 net.cpp:111] Creating Layer loss
I0607 17:39:41.173132 13702 net.cpp:478] loss <- score
I0607 17:39:41.173140 13702 net.cpp:478] loss <- label
I0607 17:39:41.173148 13702 net.cpp:434] loss -> loss
I0607 17:39:41.260035 13702 layer_factory.hpp:76] Creating layer loss
I0607 17:39:41.260318 13702 net.cpp:156] Setting up loss
I0607 17:39:41.260342 13702 net.cpp:164] Top shape: (1)
I0607 17:39:41.260356 13702 net.cpp:169]     with loss weight 1
I0607 17:39:41.260408 13702 net.cpp:237] loss needs backward computation.
I0607 17:39:41.260426 13702 net.cpp:237] score needs backward computation.
I0607 17:39:41.260439 13702 net.cpp:237] upscore needs backward computation.
I0607 17:39:41.260476 13702 net.cpp:237] score_classes needs backward computation.
I0607 17:39:41.260502 13702 net.cpp:237] drop needs backward computation.
I0607 17:39:41.260515 13702 net.cpp:237] relu4 needs backward computation.
I0607 17:39:41.260526 13702 net.cpp:237] conv4 needs backward computation.
I0607 17:39:41.260538 13702 net.cpp:237] relu3 needs backward computation.
I0607 17:39:41.260550 13702 net.cpp:237] conv3 needs backward computation.
I0607 17:39:41.260562 13702 net.cpp:237] pool2 needs backward computation.
I0607 17:39:41.260574 13702 net.cpp:237] relu2 needs backward computation.
I0607 17:39:41.260586 13702 net.cpp:237] conv2 needs backward computation.
I0607 17:39:41.260596 13702 net.cpp:237] pool1 needs backward computation.
I0607 17:39:41.260607 13702 net.cpp:237] relu1 needs backward computation.
I0607 17:39:41.260617 13702 net.cpp:237] conv1 needs backward computation.
I0607 17:39:41.260628 13702 net.cpp:241] label does not need backward computation.
I0607 17:39:41.260642 13702 net.cpp:241] data_data_0_split does not need backward computation.
I0607 17:39:41.260653 13702 net.cpp:241] data does not need backward computation.
I0607 17:39:41.260664 13702 net.cpp:284] This network produces output loss
I0607 17:39:41.260689 13702 net.cpp:298] Network initialization done.
I0607 17:39:41.260702 13702 net.cpp:299] Memory required for data: 35123108
I0607 17:39:41.261669 13702 solver.cpp:186] Creating test net (#0) specified by test_net file: fcn_test.prototxt
I0607 17:39:41.262019 13702 net.cpp:50] Initializing net from parameters: 
name: "FCN"
force_backward: true
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  transform_param {
    mirror: false
    crop_size: 0
    mean_value: 77
  }
  data_param {
    source: "val_images_lmdb/"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "label"
  type: "Data"
  top: "label"
  data_param {
    source: "val_labels_lmdb/"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 100
    pad: 50
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 200
    pad: 0
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 300
    pad: 0
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 300
    pad: 0
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "drop"
  type: "Dropout"
  bottom: "conv4"
  top: "conv4"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "score_classes"
  type: "Convolution"
  bottom: "conv4"
  top: "score_classes"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "score_classes"
  top: "upscore"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    bias_term: true
    pad: 8
    kernel_size: 31
    stride: 16
    weight_filler {
      type: "bilinear"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "score"
  type: "Crop"
  bottom: "upscore"
  bottom: "data"
  top: "score"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
  loss_param {
    normalize: true
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
}
I0607 17:39:41.262197 13702 layer_factory.hpp:76] Creating layer data
I0607 17:39:41.262285 13702 net.cpp:111] Creating Layer data
I0607 17:39:41.262306 13702 net.cpp:434] data -> data
I0607 17:39:41.287521 13716 db_lmdb.cpp:22] Opened lmdb val_images_lmdb/
I0607 17:39:41.292213 13702 data_layer.cpp:44] output data size: 1,1,256,256
I0607 17:39:41.293035 13702 net.cpp:156] Setting up data
I0607 17:39:41.293053 13702 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0607 17:39:41.293063 13702 layer_factory.hpp:76] Creating layer data_data_0_split
I0607 17:39:41.293078 13702 net.cpp:111] Creating Layer data_data_0_split
I0607 17:39:41.293086 13702 net.cpp:478] data_data_0_split <- data
I0607 17:39:41.293094 13702 net.cpp:434] data_data_0_split -> data_data_0_split_0
I0607 17:39:41.293107 13702 net.cpp:434] data_data_0_split -> data_data_0_split_1
I0607 17:39:41.293117 13702 net.cpp:156] Setting up data_data_0_split
I0607 17:39:41.293126 13702 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0607 17:39:41.293133 13702 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0607 17:39:41.293138 13702 layer_factory.hpp:76] Creating layer label
I0607 17:39:41.293184 13702 net.cpp:111] Creating Layer label
I0607 17:39:41.293195 13702 net.cpp:434] label -> label
I0607 17:39:41.328234 13718 db_lmdb.cpp:22] Opened lmdb val_labels_lmdb/
I0607 17:39:41.329159 13702 data_layer.cpp:44] output data size: 1,1,256,256
I0607 17:39:41.329932 13702 net.cpp:156] Setting up label
I0607 17:39:41.329952 13702 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0607 17:39:41.329960 13702 layer_factory.hpp:76] Creating layer label_label_0_split
I0607 17:39:41.329972 13702 net.cpp:111] Creating Layer label_label_0_split
I0607 17:39:41.329978 13702 net.cpp:478] label_label_0_split <- label
I0607 17:39:41.329989 13702 net.cpp:434] label_label_0_split -> label_label_0_split_0
I0607 17:39:41.330003 13702 net.cpp:434] label_label_0_split -> label_label_0_split_1
I0607 17:39:41.330014 13702 net.cpp:156] Setting up label_label_0_split
I0607 17:39:41.330023 13702 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0607 17:39:41.330029 13702 net.cpp:164] Top shape: 1 1 256 256 (65536)
I0607 17:39:41.330034 13702 layer_factory.hpp:76] Creating layer conv1
I0607 17:39:41.330049 13702 net.cpp:111] Creating Layer conv1
I0607 17:39:41.330054 13702 net.cpp:478] conv1 <- data_data_0_split_0
I0607 17:39:41.330062 13702 net.cpp:434] conv1 -> conv1
I0607 17:39:41.330200 13702 net.cpp:156] Setting up conv1
I0607 17:39:41.330212 13702 net.cpp:164] Top shape: 1 100 176 176 (3097600)
I0607 17:39:41.330225 13702 layer_factory.hpp:76] Creating layer relu1
I0607 17:39:41.330241 13702 net.cpp:111] Creating Layer relu1
I0607 17:39:41.330255 13702 net.cpp:478] relu1 <- conv1
I0607 17:39:41.330263 13702 net.cpp:420] relu1 -> conv1 (in-place)
I0607 17:39:41.330272 13702 net.cpp:156] Setting up relu1
I0607 17:39:41.330279 13702 net.cpp:164] Top shape: 1 100 176 176 (3097600)
I0607 17:39:41.330286 13702 layer_factory.hpp:76] Creating layer pool1
I0607 17:39:41.330293 13702 net.cpp:111] Creating Layer pool1
I0607 17:39:41.330299 13702 net.cpp:478] pool1 <- conv1
I0607 17:39:41.330307 13702 net.cpp:434] pool1 -> pool1
I0607 17:39:41.330317 13702 net.cpp:156] Setting up pool1
I0607 17:39:41.330325 13702 net.cpp:164] Top shape: 1 100 88 88 (774400)
I0607 17:39:41.330330 13702 layer_factory.hpp:76] Creating layer conv2
I0607 17:39:41.330343 13702 net.cpp:111] Creating Layer conv2
I0607 17:39:41.330348 13702 net.cpp:478] conv2 <- pool1
I0607 17:39:41.330358 13702 net.cpp:434] conv2 -> conv2
I0607 17:39:41.343511 13702 net.cpp:156] Setting up conv2
I0607 17:39:41.343551 13702 net.cpp:164] Top shape: 1 200 42 42 (352800)
I0607 17:39:41.343569 13702 layer_factory.hpp:76] Creating layer relu2
I0607 17:39:41.343583 13702 net.cpp:111] Creating Layer relu2
I0607 17:39:41.343590 13702 net.cpp:478] relu2 <- conv2
I0607 17:39:41.343598 13702 net.cpp:420] relu2 -> conv2 (in-place)
I0607 17:39:41.343611 13702 net.cpp:156] Setting up relu2
I0607 17:39:41.343617 13702 net.cpp:164] Top shape: 1 200 42 42 (352800)
I0607 17:39:41.343623 13702 layer_factory.hpp:76] Creating layer pool2
I0607 17:39:41.343631 13702 net.cpp:111] Creating Layer pool2
I0607 17:39:41.343637 13702 net.cpp:478] pool2 <- conv2
I0607 17:39:41.343647 13702 net.cpp:434] pool2 -> pool2
I0607 17:39:41.343659 13702 net.cpp:156] Setting up pool2
I0607 17:39:41.343667 13702 net.cpp:164] Top shape: 1 200 21 21 (88200)
I0607 17:39:41.343672 13702 layer_factory.hpp:76] Creating layer conv3
I0607 17:39:41.343682 13702 net.cpp:111] Creating Layer conv3
I0607 17:39:41.343688 13702 net.cpp:478] conv3 <- pool2
I0607 17:39:41.343695 13702 net.cpp:434] conv3 -> conv3
I0607 17:39:41.357666 13702 net.cpp:156] Setting up conv3
I0607 17:39:41.357700 13702 net.cpp:164] Top shape: 1 300 19 19 (108300)
I0607 17:39:41.357717 13702 layer_factory.hpp:76] Creating layer relu3
I0607 17:39:41.357728 13702 net.cpp:111] Creating Layer relu3
I0607 17:39:41.357735 13702 net.cpp:478] relu3 <- conv3
I0607 17:39:41.357756 13702 net.cpp:420] relu3 -> conv3 (in-place)
I0607 17:39:41.357774 13702 net.cpp:156] Setting up relu3
I0607 17:39:41.357781 13702 net.cpp:164] Top shape: 1 300 19 19 (108300)
I0607 17:39:41.357786 13702 layer_factory.hpp:76] Creating layer conv4
I0607 17:39:41.357798 13702 net.cpp:111] Creating Layer conv4
I0607 17:39:41.357805 13702 net.cpp:478] conv4 <- conv3
I0607 17:39:41.357813 13702 net.cpp:434] conv4 -> conv4
I0607 17:39:41.378309 13702 net.cpp:156] Setting up conv4
I0607 17:39:41.378345 13702 net.cpp:164] Top shape: 1 300 17 17 (86700)
I0607 17:39:41.378357 13702 layer_factory.hpp:76] Creating layer relu4
I0607 17:39:41.378368 13702 net.cpp:111] Creating Layer relu4
I0607 17:39:41.378376 13702 net.cpp:478] relu4 <- conv4
I0607 17:39:41.378386 13702 net.cpp:420] relu4 -> conv4 (in-place)
I0607 17:39:41.378398 13702 net.cpp:156] Setting up relu4
I0607 17:39:41.378406 13702 net.cpp:164] Top shape: 1 300 17 17 (86700)
I0607 17:39:41.378410 13702 layer_factory.hpp:76] Creating layer drop
I0607 17:39:41.378419 13702 net.cpp:111] Creating Layer drop
I0607 17:39:41.378425 13702 net.cpp:478] drop <- conv4
I0607 17:39:41.378432 13702 net.cpp:420] drop -> conv4 (in-place)
I0607 17:39:41.378442 13702 net.cpp:156] Setting up drop
I0607 17:39:41.378448 13702 net.cpp:164] Top shape: 1 300 17 17 (86700)
I0607 17:39:41.378453 13702 layer_factory.hpp:76] Creating layer score_classes
I0607 17:39:41.378465 13702 net.cpp:111] Creating Layer score_classes
I0607 17:39:41.378471 13702 net.cpp:478] score_classes <- conv4
I0607 17:39:41.378479 13702 net.cpp:434] score_classes -> score_classes
I0607 17:39:41.378551 13702 net.cpp:156] Setting up score_classes
I0607 17:39:41.378571 13702 net.cpp:164] Top shape: 1 2 17 17 (578)
I0607 17:39:41.378592 13702 layer_factory.hpp:76] Creating layer upscore
I0607 17:39:41.378607 13702 net.cpp:111] Creating Layer upscore
I0607 17:39:41.378612 13702 net.cpp:478] upscore <- score_classes
I0607 17:39:41.378620 13702 net.cpp:434] upscore -> upscore
I0607 17:39:41.379207 13702 net.cpp:156] Setting up upscore
I0607 17:39:41.379221 13702 net.cpp:164] Top shape: 1 2 271 271 (146882)
I0607 17:39:41.379230 13702 layer_factory.hpp:76] Creating layer score
I0607 17:39:41.379238 13702 net.cpp:111] Creating Layer score
I0607 17:39:41.379245 13702 net.cpp:478] score <- upscore
I0607 17:39:41.379251 13702 net.cpp:478] score <- data_data_0_split_1
I0607 17:39:41.379257 13702 net.cpp:434] score -> score
I0607 17:39:41.379287 13702 net.cpp:156] Setting up score
I0607 17:39:41.379294 13702 net.cpp:164] Top shape: 1 2 256 256 (131072)
I0607 17:39:41.379300 13702 layer_factory.hpp:76] Creating layer score_score_0_split
I0607 17:39:41.379310 13702 net.cpp:111] Creating Layer score_score_0_split
I0607 17:39:41.379317 13702 net.cpp:478] score_score_0_split <- score
I0607 17:39:41.379323 13702 net.cpp:434] score_score_0_split -> score_score_0_split_0
I0607 17:39:41.379333 13702 net.cpp:434] score_score_0_split -> score_score_0_split_1
I0607 17:39:41.379343 13702 net.cpp:156] Setting up score_score_0_split
I0607 17:39:41.379351 13702 net.cpp:164] Top shape: 1 2 256 256 (131072)
I0607 17:39:41.379359 13702 net.cpp:164] Top shape: 1 2 256 256 (131072)
I0607 17:39:41.379364 13702 layer_factory.hpp:76] Creating layer loss
I0607 17:39:41.379371 13702 net.cpp:111] Creating Layer loss
I0607 17:39:41.379377 13702 net.cpp:478] loss <- score_score_0_split_0
I0607 17:39:41.379384 13702 net.cpp:478] loss <- label_label_0_split_0
I0607 17:39:41.379390 13702 net.cpp:434] loss -> loss
I0607 17:39:41.379400 13702 layer_factory.hpp:76] Creating layer loss
I0607 17:39:41.379524 13702 net.cpp:156] Setting up loss
I0607 17:39:41.379536 13702 net.cpp:164] Top shape: (1)
I0607 17:39:41.379542 13702 net.cpp:169]     with loss weight 1
I0607 17:39:41.379555 13702 layer_factory.hpp:76] Creating layer accuracy
I0607 17:39:41.379567 13702 net.cpp:111] Creating Layer accuracy
I0607 17:39:41.379573 13702 net.cpp:478] accuracy <- score_score_0_split_1
I0607 17:39:41.379580 13702 net.cpp:478] accuracy <- label_label_0_split_1
I0607 17:39:41.379587 13702 net.cpp:434] accuracy -> accuracy
I0607 17:39:41.379598 13702 net.cpp:156] Setting up accuracy
I0607 17:39:41.379606 13702 net.cpp:164] Top shape: (1)
I0607 17:39:41.379611 13702 net.cpp:241] accuracy does not need backward computation.
I0607 17:39:41.379616 13702 net.cpp:237] loss needs backward computation.
I0607 17:39:41.379622 13702 net.cpp:237] score_score_0_split needs backward computation.
I0607 17:39:41.379628 13702 net.cpp:237] score needs backward computation.
I0607 17:39:41.379633 13702 net.cpp:237] upscore needs backward computation.
I0607 17:39:41.379639 13702 net.cpp:237] score_classes needs backward computation.
I0607 17:39:41.379644 13702 net.cpp:237] drop needs backward computation.
I0607 17:39:41.379649 13702 net.cpp:237] relu4 needs backward computation.
I0607 17:39:41.379654 13702 net.cpp:237] conv4 needs backward computation.
I0607 17:39:41.379659 13702 net.cpp:237] relu3 needs backward computation.
I0607 17:39:41.379665 13702 net.cpp:237] conv3 needs backward computation.
I0607 17:39:41.379670 13702 net.cpp:237] pool2 needs backward computation.
I0607 17:39:41.379675 13702 net.cpp:237] relu2 needs backward computation.
I0607 17:39:41.379680 13702 net.cpp:237] conv2 needs backward computation.
I0607 17:39:41.379685 13702 net.cpp:237] pool1 needs backward computation.
I0607 17:39:41.379691 13702 net.cpp:237] relu1 needs backward computation.
I0607 17:39:41.379696 13702 net.cpp:237] conv1 needs backward computation.
I0607 17:39:41.379703 13702 net.cpp:241] label_label_0_split does not need backward computation.
I0607 17:39:41.379710 13702 net.cpp:241] label does not need backward computation.
I0607 17:39:41.379715 13702 net.cpp:241] data_data_0_split does not need backward computation.
I0607 17:39:41.379730 13702 net.cpp:241] data does not need backward computation.
I0607 17:39:41.379736 13702 net.cpp:284] This network produces output accuracy
I0607 17:39:41.379742 13702 net.cpp:284] This network produces output loss
I0607 17:39:41.379757 13702 net.cpp:298] Network initialization done.
I0607 17:39:41.379762 13702 net.cpp:299] Memory required for data: 36695976
I0607 17:39:41.379829 13702 solver.cpp:65] Solver scaffolding done.
I0607 17:39:41.379861 13702 caffe.cpp:211] Starting Optimization
I0607 17:39:41.379870 13702 solver.cpp:293] Solving FCN
I0607 17:39:41.379875 13702 solver.cpp:294] Learning Rate Policy: multistep
I0607 17:39:41.380594 13702 solver.cpp:346] Iteration 0, Testing net (#0)
I0607 17:39:41.854800 13702 solver.cpp:414]     Test net output #0: accuracy = 0.0122205
I0607 17:39:41.854840 13702 solver.cpp:414]     Test net output #1: loss = 0.693147 (* 1 = 0.693147 loss)
I0607 17:39:41.870302 13702 solver.cpp:242] Iteration 0, loss = 0.693147
I0607 17:39:41.870331 13702 solver.cpp:258]     Train net output #0: loss = 0.693147 (* 1 = 0.693147 loss)
I0607 17:39:41.870349 13702 solver.cpp:571] Iteration 0, lr = 0.01
I0607 17:39:42.229686 13702 blocking_queue.cpp:50] Data layer prefetch queue empty
I0607 17:39:44.263933 13702 solver.cpp:346] Iteration 200, Testing net (#0)
I0607 17:39:44.721854 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:39:44.721896 13702 solver.cpp:414]     Test net output #1: loss = 0.068096 (* 1 = 0.068096 loss)
I0607 17:39:44.725677 13702 solver.cpp:242] Iteration 200, loss = 0.124643
I0607 17:39:44.725697 13702 solver.cpp:258]     Train net output #0: loss = 0.0963681 (* 1 = 0.0963681 loss)
I0607 17:39:44.725708 13702 solver.cpp:571] Iteration 200, lr = 0.01
I0607 17:39:47.036777 13702 solver.cpp:346] Iteration 400, Testing net (#0)
I0607 17:39:47.497097 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:39:47.497138 13702 solver.cpp:414]     Test net output #1: loss = 0.0668763 (* 1 = 0.0668763 loss)
I0607 17:39:47.500994 13702 solver.cpp:242] Iteration 400, loss = 0.0848631
I0607 17:39:47.501014 13702 solver.cpp:258]     Train net output #0: loss = 0.110462 (* 1 = 0.110462 loss)
I0607 17:39:47.501024 13702 solver.cpp:571] Iteration 400, lr = 0.01
I0607 17:39:49.824847 13702 solver.cpp:346] Iteration 600, Testing net (#0)
I0607 17:39:50.281909 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:39:50.281951 13702 solver.cpp:414]     Test net output #1: loss = 0.0667621 (* 1 = 0.0667621 loss)
I0607 17:39:50.285511 13702 solver.cpp:242] Iteration 600, loss = 0.0860599
I0607 17:39:50.285531 13702 solver.cpp:258]     Train net output #0: loss = 0.0248629 (* 1 = 0.0248629 loss)
I0607 17:39:50.285542 13702 solver.cpp:571] Iteration 600, lr = 0.01
I0607 17:39:52.607435 13702 solver.cpp:346] Iteration 800, Testing net (#0)
I0607 17:39:53.070384 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:39:53.070423 13702 solver.cpp:414]     Test net output #1: loss = 0.0666543 (* 1 = 0.0666543 loss)
I0607 17:39:53.073974 13702 solver.cpp:242] Iteration 800, loss = 0.0864819
I0607 17:39:53.073995 13702 solver.cpp:258]     Train net output #0: loss = 0.0717611 (* 1 = 0.0717611 loss)
I0607 17:39:53.074007 13702 solver.cpp:571] Iteration 800, lr = 0.01
I0607 17:39:55.391366 13702 solver.cpp:346] Iteration 1000, Testing net (#0)
I0607 17:39:55.850703 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:39:55.850733 13702 solver.cpp:414]     Test net output #1: loss = 0.0666727 (* 1 = 0.0666727 loss)
I0607 17:39:55.854492 13702 solver.cpp:242] Iteration 1000, loss = 0.085587
I0607 17:39:55.854512 13702 solver.cpp:258]     Train net output #0: loss = 0.121322 (* 1 = 0.121322 loss)
I0607 17:39:55.854522 13702 solver.cpp:571] Iteration 1000, lr = 0.01
I0607 17:39:58.171190 13702 solver.cpp:346] Iteration 1200, Testing net (#0)
I0607 17:39:58.619366 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:39:58.619427 13702 solver.cpp:414]     Test net output #1: loss = 0.0668194 (* 1 = 0.0668194 loss)
I0607 17:39:58.623005 13702 solver.cpp:242] Iteration 1200, loss = 0.0870601
I0607 17:39:58.623025 13702 solver.cpp:258]     Train net output #0: loss = 0.069662 (* 1 = 0.069662 loss)
I0607 17:39:58.623035 13702 solver.cpp:571] Iteration 1200, lr = 0.01
I0607 17:40:00.942559 13702 solver.cpp:346] Iteration 1400, Testing net (#0)
I0607 17:40:01.388031 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:40:01.388070 13702 solver.cpp:414]     Test net output #1: loss = 0.0667791 (* 1 = 0.0667791 loss)
I0607 17:40:01.391844 13702 solver.cpp:242] Iteration 1400, loss = 0.0863194
I0607 17:40:01.391865 13702 solver.cpp:258]     Train net output #0: loss = 0.165953 (* 1 = 0.165953 loss)
I0607 17:40:01.391875 13702 solver.cpp:571] Iteration 1400, lr = 0.01
I0607 17:40:03.713228 13702 solver.cpp:346] Iteration 1600, Testing net (#0)
I0607 17:40:04.165107 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:40:04.165143 13702 solver.cpp:414]     Test net output #1: loss = 0.0666775 (* 1 = 0.0666775 loss)
I0607 17:40:04.168668 13702 solver.cpp:242] Iteration 1600, loss = 0.0844813
I0607 17:40:04.168687 13702 solver.cpp:258]     Train net output #0: loss = 0.122735 (* 1 = 0.122735 loss)
I0607 17:40:04.168697 13702 solver.cpp:571] Iteration 1600, lr = 0.01
I0607 17:40:06.490841 13702 solver.cpp:346] Iteration 1800, Testing net (#0)
I0607 17:40:06.936669 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:40:06.936709 13702 solver.cpp:414]     Test net output #1: loss = 0.0666604 (* 1 = 0.0666604 loss)
I0607 17:40:06.940309 13702 solver.cpp:242] Iteration 1800, loss = 0.0848136
I0607 17:40:06.940328 13702 solver.cpp:258]     Train net output #0: loss = 0.0388373 (* 1 = 0.0388373 loss)
I0607 17:40:06.940338 13702 solver.cpp:571] Iteration 1800, lr = 0.01
I0607 17:40:09.260538 13702 solver.cpp:346] Iteration 2000, Testing net (#0)
I0607 17:40:09.721482 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:40:09.721523 13702 solver.cpp:414]     Test net output #1: loss = 0.0667209 (* 1 = 0.0667209 loss)
I0607 17:40:09.725327 13702 solver.cpp:242] Iteration 2000, loss = 0.0867066
I0607 17:40:09.725348 13702 solver.cpp:258]     Train net output #0: loss = 0.0649951 (* 1 = 0.0649951 loss)
I0607 17:40:09.725359 13702 solver.cpp:571] Iteration 2000, lr = 0.01
I0607 17:40:12.047075 13702 solver.cpp:346] Iteration 2200, Testing net (#0)
I0607 17:40:12.512485 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:40:12.512526 13702 solver.cpp:414]     Test net output #1: loss = 0.0666097 (* 1 = 0.0666097 loss)
I0607 17:40:12.516062 13702 solver.cpp:242] Iteration 2200, loss = 0.0855923
I0607 17:40:12.516082 13702 solver.cpp:258]     Train net output #0: loss = 0.111218 (* 1 = 0.111218 loss)
I0607 17:40:12.516093 13702 solver.cpp:571] Iteration 2200, lr = 0.01
I0607 17:40:14.837925 13702 solver.cpp:346] Iteration 2400, Testing net (#0)
I0607 17:40:15.290036 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:40:15.290076 13702 solver.cpp:414]     Test net output #1: loss = 0.0666833 (* 1 = 0.0666833 loss)
I0607 17:40:15.293895 13702 solver.cpp:242] Iteration 2400, loss = 0.0857068
I0607 17:40:15.293916 13702 solver.cpp:258]     Train net output #0: loss = 0.0561457 (* 1 = 0.0561457 loss)
I0607 17:40:15.293927 13702 solver.cpp:571] Iteration 2400, lr = 0.01
I0607 17:40:16.448679 13702 solver.cpp:449] Snapshotting to binary proto file ./model_logs/fcn_iter_2500.caffemodel
I0607 17:40:16.495076 13702 solver.cpp:734] Snapshotting solver state to binary proto file./model_logs/fcn_iter_2500.solverstate
I0607 17:40:17.723793 13702 solver.cpp:346] Iteration 2600, Testing net (#0)
I0607 17:40:18.172374 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:40:18.172412 13702 solver.cpp:414]     Test net output #1: loss = 0.0668244 (* 1 = 0.0668244 loss)
I0607 17:40:18.176223 13702 solver.cpp:242] Iteration 2600, loss = 0.0872665
I0607 17:40:18.176251 13702 solver.cpp:258]     Train net output #0: loss = 0.0507587 (* 1 = 0.0507587 loss)
I0607 17:40:18.176264 13702 solver.cpp:571] Iteration 2600, lr = 0.01
I0607 17:40:20.500187 13702 solver.cpp:346] Iteration 2800, Testing net (#0)
I0607 17:40:20.951819 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:40:20.951860 13702 solver.cpp:414]     Test net output #1: loss = 0.0667422 (* 1 = 0.0667422 loss)
I0607 17:40:20.955466 13702 solver.cpp:242] Iteration 2800, loss = 0.08611
I0607 17:40:20.955484 13702 solver.cpp:258]     Train net output #0: loss = 0.0906878 (* 1 = 0.0906878 loss)
I0607 17:40:20.955495 13702 solver.cpp:571] Iteration 2800, lr = 0.01
I0607 17:40:23.279819 13702 solver.cpp:346] Iteration 3000, Testing net (#0)
I0607 17:40:23.733019 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:40:23.733058 13702 solver.cpp:414]     Test net output #1: loss = 0.0666637 (* 1 = 0.0666637 loss)
I0607 17:40:23.736830 13702 solver.cpp:242] Iteration 3000, loss = 0.0840269
I0607 17:40:23.736850 13702 solver.cpp:258]     Train net output #0: loss = 0.0738771 (* 1 = 0.0738771 loss)
I0607 17:40:23.736860 13702 solver.cpp:571] Iteration 3000, lr = 0.01
I0607 17:40:26.084672 13702 solver.cpp:346] Iteration 3200, Testing net (#0)
I0607 17:40:26.544577 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:40:26.544616 13702 solver.cpp:414]     Test net output #1: loss = 0.0666523 (* 1 = 0.0666523 loss)
I0607 17:40:26.548307 13702 solver.cpp:242] Iteration 3200, loss = 0.0858632
I0607 17:40:26.548327 13702 solver.cpp:258]     Train net output #0: loss = 0.0226277 (* 1 = 0.0226277 loss)
I0607 17:40:26.548337 13702 solver.cpp:571] Iteration 3200, lr = 0.01
I0607 17:40:28.970793 13702 solver.cpp:346] Iteration 3400, Testing net (#0)
I0607 17:40:29.439811 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:40:29.439851 13702 solver.cpp:414]     Test net output #1: loss = 0.0667061 (* 1 = 0.0667061 loss)
I0607 17:40:29.443891 13702 solver.cpp:242] Iteration 3400, loss = 0.0866083
I0607 17:40:29.443912 13702 solver.cpp:258]     Train net output #0: loss = 0.0858459 (* 1 = 0.0858459 loss)
I0607 17:40:29.443922 13702 solver.cpp:571] Iteration 3400, lr = 0.01
I0607 17:40:31.996227 13702 solver.cpp:346] Iteration 3600, Testing net (#0)
I0607 17:40:32.456765 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:40:32.456804 13702 solver.cpp:414]     Test net output #1: loss = 0.066573 (* 1 = 0.066573 loss)
I0607 17:40:32.461088 13702 solver.cpp:242] Iteration 3600, loss = 0.084766
I0607 17:40:32.461108 13702 solver.cpp:258]     Train net output #0: loss = 0.10924 (* 1 = 0.10924 loss)
I0607 17:40:32.461118 13702 solver.cpp:571] Iteration 3600, lr = 0.01
I0607 17:40:35.117458 13702 solver.cpp:346] Iteration 3800, Testing net (#0)
I0607 17:40:35.586010 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:40:35.586051 13702 solver.cpp:414]     Test net output #1: loss = 0.0666664 (* 1 = 0.0666664 loss)
I0607 17:40:35.590466 13702 solver.cpp:242] Iteration 3800, loss = 0.0860357
I0607 17:40:35.590487 13702 solver.cpp:258]     Train net output #0: loss = 0.0490512 (* 1 = 0.0490512 loss)
I0607 17:40:35.590497 13702 solver.cpp:571] Iteration 3800, lr = 0.01
I0607 17:40:38.313805 13702 solver.cpp:346] Iteration 4000, Testing net (#0)
I0607 17:40:38.778241 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:40:38.778292 13702 solver.cpp:414]     Test net output #1: loss = 0.0667836 (* 1 = 0.0667836 loss)
I0607 17:40:38.782675 13702 solver.cpp:242] Iteration 4000, loss = 0.0873519
I0607 17:40:38.782694 13702 solver.cpp:258]     Train net output #0: loss = 0.0893138 (* 1 = 0.0893138 loss)
I0607 17:40:38.782704 13702 solver.cpp:571] Iteration 4000, lr = 0.01
I0607 17:40:41.504505 13702 solver.cpp:346] Iteration 4200, Testing net (#0)
I0607 17:40:41.973837 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:40:41.973884 13702 solver.cpp:414]     Test net output #1: loss = 0.0666052 (* 1 = 0.0666052 loss)
I0607 17:40:41.978296 13702 solver.cpp:242] Iteration 4200, loss = 0.0852289
I0607 17:40:41.978317 13702 solver.cpp:258]     Train net output #0: loss = 0.0861586 (* 1 = 0.0861586 loss)
I0607 17:40:41.978328 13702 solver.cpp:571] Iteration 4200, lr = 0.01
I0607 17:40:44.704802 13702 solver.cpp:346] Iteration 4400, Testing net (#0)
I0607 17:40:45.174756 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:40:45.174795 13702 solver.cpp:414]     Test net output #1: loss = 0.0663444 (* 1 = 0.0663444 loss)
I0607 17:40:45.178880 13702 solver.cpp:242] Iteration 4400, loss = 0.0847723
I0607 17:40:45.178900 13702 solver.cpp:258]     Train net output #0: loss = 0.124443 (* 1 = 0.124443 loss)
I0607 17:40:45.178911 13702 solver.cpp:571] Iteration 4400, lr = 0.01
I0607 17:40:47.897228 13702 solver.cpp:346] Iteration 4600, Testing net (#0)
I0607 17:40:48.356468 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:40:48.356508 13702 solver.cpp:414]     Test net output #1: loss = 0.0638865 (* 1 = 0.0638865 loss)
I0607 17:40:48.360563 13702 solver.cpp:242] Iteration 4600, loss = 0.0843865
I0607 17:40:48.360589 13702 solver.cpp:258]     Train net output #0: loss = 0.0845888 (* 1 = 0.0845888 loss)
I0607 17:40:48.360608 13702 solver.cpp:571] Iteration 4600, lr = 0.01
I0607 17:40:51.083446 13702 solver.cpp:346] Iteration 4800, Testing net (#0)
I0607 17:40:51.557771 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:40:51.557811 13702 solver.cpp:414]     Test net output #1: loss = 0.0537013 (* 1 = 0.0537013 loss)
I0607 17:40:51.561939 13702 solver.cpp:242] Iteration 4800, loss = 0.0786229
I0607 17:40:51.561959 13702 solver.cpp:258]     Train net output #0: loss = 0.0130804 (* 1 = 0.0130804 loss)
I0607 17:40:51.561969 13702 solver.cpp:571] Iteration 4800, lr = 0.01
I0607 17:40:54.283258 13702 solver.cpp:449] Snapshotting to binary proto file ./model_logs/fcn_iter_5000.caffemodel
I0607 17:40:54.380316 13702 solver.cpp:734] Snapshotting solver state to binary proto file./model_logs/fcn_iter_5000.solverstate
I0607 17:40:54.479842 13702 solver.cpp:346] Iteration 5000, Testing net (#0)
I0607 17:40:54.955169 13702 solver.cpp:414]     Test net output #0: accuracy = 0.987779
I0607 17:40:54.955212 13702 solver.cpp:414]     Test net output #1: loss = 0.0446631 (* 1 = 0.0446631 loss)
I0607 17:40:54.959300 13702 solver.cpp:242] Iteration 5000, loss = 0.0626998
I0607 17:40:54.959321 13702 solver.cpp:258]     Train net output #0: loss = 0.114304 (* 1 = 0.114304 loss)
I0607 17:40:54.959332 13702 solver.cpp:571] Iteration 5000, lr = 0.01
I0607 17:40:57.683537 13702 solver.cpp:346] Iteration 5200, Testing net (#0)
I0607 17:40:58.161768 13702 solver.cpp:414]     Test net output #0: accuracy = 0.989494
I0607 17:40:58.161808 13702 solver.cpp:414]     Test net output #1: loss = 0.0333893 (* 1 = 0.0333893 loss)
I0607 17:40:58.166220 13702 solver.cpp:242] Iteration 5200, loss = 0.0501035
I0607 17:40:58.166241 13702 solver.cpp:258]     Train net output #0: loss = 0.041204 (* 1 = 0.041204 loss)
I0607 17:40:58.166252 13702 solver.cpp:571] Iteration 5200, lr = 0.01
I0607 17:41:00.890836 13702 solver.cpp:346] Iteration 5400, Testing net (#0)
I0607 17:41:01.374855 13702 solver.cpp:414]     Test net output #0: accuracy = 0.989124
I0607 17:41:01.374897 13702 solver.cpp:414]     Test net output #1: loss = 0.0359373 (* 1 = 0.0359373 loss)
I0607 17:41:01.379267 13702 solver.cpp:242] Iteration 5400, loss = 0.042129
I0607 17:41:01.379288 13702 solver.cpp:258]     Train net output #0: loss = 0.0181258 (* 1 = 0.0181258 loss)
I0607 17:41:01.379299 13702 solver.cpp:571] Iteration 5400, lr = 0.01
I0607 17:41:04.098279 13702 solver.cpp:346] Iteration 5600, Testing net (#0)
I0607 17:41:04.567729 13702 solver.cpp:414]     Test net output #0: accuracy = 0.992116
I0607 17:41:04.567771 13702 solver.cpp:414]     Test net output #1: loss = 0.0221736 (* 1 = 0.0221736 loss)
I0607 17:41:04.572190 13702 solver.cpp:242] Iteration 5600, loss = 0.0338738
I0607 17:41:04.572216 13702 solver.cpp:258]     Train net output #0: loss = 0.0281944 (* 1 = 0.0281944 loss)
I0607 17:41:04.572227 13702 solver.cpp:571] Iteration 5600, lr = 0.01
I0607 17:41:07.293936 13702 solver.cpp:346] Iteration 5800, Testing net (#0)
I0607 17:41:07.765180 13702 solver.cpp:414]     Test net output #0: accuracy = 0.992405
I0607 17:41:07.765219 13702 solver.cpp:414]     Test net output #1: loss = 0.0202553 (* 1 = 0.0202553 loss)
I0607 17:41:07.769601 13702 solver.cpp:242] Iteration 5800, loss = 0.0264389
I0607 17:41:07.769620 13702 solver.cpp:258]     Train net output #0: loss = 0.0101809 (* 1 = 0.0101809 loss)
I0607 17:41:07.769631 13702 solver.cpp:571] Iteration 5800, lr = 0.01
I0607 17:41:10.490929 13702 solver.cpp:346] Iteration 6000, Testing net (#0)
I0607 17:41:10.954818 13702 solver.cpp:414]     Test net output #0: accuracy = 0.991583
I0607 17:41:10.954857 13702 solver.cpp:414]     Test net output #1: loss = 0.0222209 (* 1 = 0.0222209 loss)
I0607 17:41:10.959280 13702 solver.cpp:242] Iteration 6000, loss = 0.0220698
I0607 17:41:10.959298 13702 solver.cpp:258]     Train net output #0: loss = 0.0188399 (* 1 = 0.0188399 loss)
I0607 17:41:10.959308 13702 solver.cpp:571] Iteration 6000, lr = 0.01
I0607 17:41:13.680061 13702 solver.cpp:346] Iteration 6200, Testing net (#0)
I0607 17:41:14.150668 13702 solver.cpp:414]     Test net output #0: accuracy = 0.993541
I0607 17:41:14.150703 13702 solver.cpp:414]     Test net output #1: loss = 0.0160722 (* 1 = 0.0160722 loss)
I0607 17:41:14.155134 13702 solver.cpp:242] Iteration 6200, loss = 0.0192066
I0607 17:41:14.155153 13702 solver.cpp:258]     Train net output #0: loss = 0.0405706 (* 1 = 0.0405706 loss)
I0607 17:41:14.155164 13702 solver.cpp:571] Iteration 6200, lr = 0.01
I0607 17:41:16.878671 13702 solver.cpp:346] Iteration 6400, Testing net (#0)
I0607 17:41:17.342005 13702 solver.cpp:414]     Test net output #0: accuracy = 0.994008
I0607 17:41:17.342046 13702 solver.cpp:414]     Test net output #1: loss = 0.0162961 (* 1 = 0.0162961 loss)
I0607 17:41:17.346469 13702 solver.cpp:242] Iteration 6400, loss = 0.0158365
I0607 17:41:17.346489 13702 solver.cpp:258]     Train net output #0: loss = 0.00881746 (* 1 = 0.00881746 loss)
I0607 17:41:17.346499 13702 solver.cpp:571] Iteration 6400, lr = 0.01
I0607 17:41:20.069160 13702 solver.cpp:346] Iteration 6600, Testing net (#0)
I0607 17:41:20.543644 13702 solver.cpp:414]     Test net output #0: accuracy = 0.994421
I0607 17:41:20.543684 13702 solver.cpp:414]     Test net output #1: loss = 0.0142049 (* 1 = 0.0142049 loss)
I0607 17:41:20.547786 13702 solver.cpp:242] Iteration 6600, loss = 0.0144963
I0607 17:41:20.547806 13702 solver.cpp:258]     Train net output #0: loss = 0.00511445 (* 1 = 0.00511445 loss)
I0607 17:41:20.547816 13702 solver.cpp:571] Iteration 6600, lr = 0.01
I0607 17:41:23.269701 13702 solver.cpp:346] Iteration 6800, Testing net (#0)
I0607 17:41:23.735560 13702 solver.cpp:414]     Test net output #0: accuracy = 0.995094
I0607 17:41:23.735613 13702 solver.cpp:414]     Test net output #1: loss = 0.0123694 (* 1 = 0.0123694 loss)
I0607 17:41:23.739984 13702 solver.cpp:242] Iteration 6800, loss = 0.0127792
I0607 17:41:23.740003 13702 solver.cpp:258]     Train net output #0: loss = 0.00984454 (* 1 = 0.00984454 loss)
I0607 17:41:23.740013 13702 solver.cpp:571] Iteration 6800, lr = 0.01
I0607 17:41:26.464814 13702 solver.cpp:346] Iteration 7000, Testing net (#0)
I0607 17:41:26.935891 13702 solver.cpp:414]     Test net output #0: accuracy = 0.995268
I0607 17:41:26.935930 13702 solver.cpp:414]     Test net output #1: loss = 0.0136433 (* 1 = 0.0136433 loss)
I0607 17:41:26.940376 13702 solver.cpp:242] Iteration 7000, loss = 0.0111424
I0607 17:41:26.940404 13702 solver.cpp:258]     Train net output #0: loss = 0.00934396 (* 1 = 0.00934396 loss)
I0607 17:41:26.940414 13702 solver.cpp:571] Iteration 7000, lr = 0.01
I0607 17:41:29.658481 13702 solver.cpp:346] Iteration 7200, Testing net (#0)
I0607 17:41:30.118037 13702 solver.cpp:414]     Test net output #0: accuracy = 0.995737
I0607 17:41:30.118078 13702 solver.cpp:414]     Test net output #1: loss = 0.0110361 (* 1 = 0.0110361 loss)
I0607 17:41:30.122419 13702 solver.cpp:242] Iteration 7200, loss = 0.0102126
I0607 17:41:30.122445 13702 solver.cpp:258]     Train net output #0: loss = 0.0113485 (* 1 = 0.0113485 loss)
I0607 17:41:30.122455 13702 solver.cpp:571] Iteration 7200, lr = 0.01
I0607 17:41:32.840726 13702 solver.cpp:346] Iteration 7400, Testing net (#0)
I0607 17:41:33.315676 13702 solver.cpp:414]     Test net output #0: accuracy = 0.995321
I0607 17:41:33.315719 13702 solver.cpp:414]     Test net output #1: loss = 0.0118585 (* 1 = 0.0118585 loss)
I0607 17:41:33.320093 13702 solver.cpp:242] Iteration 7400, loss = 0.00915576
I0607 17:41:33.320113 13702 solver.cpp:258]     Train net output #0: loss = 0.0136468 (* 1 = 0.0136468 loss)
I0607 17:41:33.320124 13702 solver.cpp:571] Iteration 7400, lr = 0.01
I0607 17:41:34.675331 13702 solver.cpp:449] Snapshotting to binary proto file ./model_logs/fcn_iter_7500.caffemodel
I0607 17:41:34.827951 13702 solver.cpp:734] Snapshotting solver state to binary proto file./model_logs/fcn_iter_7500.solverstate
I0607 17:41:36.214540 13702 solver.cpp:346] Iteration 7600, Testing net (#0)
I0607 17:41:36.679767 13702 solver.cpp:414]     Test net output #0: accuracy = 0.996304
I0607 17:41:36.679808 13702 solver.cpp:414]     Test net output #1: loss = 0.00940341 (* 1 = 0.00940341 loss)
I0607 17:41:36.684164 13702 solver.cpp:242] Iteration 7600, loss = 0.00832524
I0607 17:41:36.684183 13702 solver.cpp:258]     Train net output #0: loss = 0.016266 (* 1 = 0.016266 loss)
I0607 17:41:36.684195 13702 solver.cpp:571] Iteration 7600, lr = 0.01
I0607 17:41:39.404402 13702 solver.cpp:346] Iteration 7800, Testing net (#0)
I0607 17:41:39.861954 13702 solver.cpp:414]     Test net output #0: accuracy = 0.994914
I0607 17:41:39.861999 13702 solver.cpp:414]     Test net output #1: loss = 0.0127127 (* 1 = 0.0127127 loss)
I0607 17:41:39.866443 13702 solver.cpp:242] Iteration 7800, loss = 0.00756535
I0607 17:41:39.866474 13702 solver.cpp:258]     Train net output #0: loss = 0.0100288 (* 1 = 0.0100288 loss)
I0607 17:41:39.866485 13702 solver.cpp:571] Iteration 7800, lr = 0.01
I0607 17:41:42.589267 13702 solver.cpp:346] Iteration 8000, Testing net (#0)
I0607 17:41:43.059891 13702 solver.cpp:414]     Test net output #0: accuracy = 0.995849
I0607 17:41:43.059932 13702 solver.cpp:414]     Test net output #1: loss = 0.0105205 (* 1 = 0.0105205 loss)
I0607 17:41:43.064272 13702 solver.cpp:242] Iteration 8000, loss = 0.0070386
I0607 17:41:43.064292 13702 solver.cpp:258]     Train net output #0: loss = 0.00749707 (* 1 = 0.00749707 loss)
I0607 17:41:43.064303 13702 solver.cpp:571] Iteration 8000, lr = 0.01
I0607 17:41:45.789445 13702 solver.cpp:346] Iteration 8200, Testing net (#0)
I0607 17:41:46.261734 13702 solver.cpp:414]     Test net output #0: accuracy = 0.996323
I0607 17:41:46.261778 13702 solver.cpp:414]     Test net output #1: loss = 0.00941552 (* 1 = 0.00941552 loss)
I0607 17:41:46.266182 13702 solver.cpp:242] Iteration 8200, loss = 0.00675391
I0607 17:41:46.266202 13702 solver.cpp:258]     Train net output #0: loss = 0.00367543 (* 1 = 0.00367543 loss)
I0607 17:41:46.266212 13702 solver.cpp:571] Iteration 8200, lr = 0.01
I0607 17:41:48.985467 13702 solver.cpp:346] Iteration 8400, Testing net (#0)
I0607 17:41:49.444438 13702 solver.cpp:414]     Test net output #0: accuracy = 0.996571
I0607 17:41:49.444475 13702 solver.cpp:414]     Test net output #1: loss = 0.00937194 (* 1 = 0.00937194 loss)
I0607 17:41:49.448884 13702 solver.cpp:242] Iteration 8400, loss = 0.0062744
I0607 17:41:49.448904 13702 solver.cpp:258]     Train net output #0: loss = 0.00471162 (* 1 = 0.00471162 loss)
I0607 17:41:49.448915 13702 solver.cpp:571] Iteration 8400, lr = 0.01
I0607 17:41:52.171416 13702 solver.cpp:346] Iteration 8600, Testing net (#0)
I0607 17:41:52.645535 13702 solver.cpp:414]     Test net output #0: accuracy = 0.995756
I0607 17:41:52.645576 13702 solver.cpp:414]     Test net output #1: loss = 0.0131022 (* 1 = 0.0131022 loss)
I0607 17:41:52.649917 13702 solver.cpp:242] Iteration 8600, loss = 0.00595294
I0607 17:41:52.649946 13702 solver.cpp:258]     Train net output #0: loss = 0.00402206 (* 1 = 0.00402206 loss)
I0607 17:41:52.649958 13702 solver.cpp:571] Iteration 8600, lr = 0.01
I0607 17:41:55.368052 13702 solver.cpp:346] Iteration 8800, Testing net (#0)
I0607 17:41:55.838953 13702 solver.cpp:414]     Test net output #0: accuracy = 0.99668
I0607 17:41:55.838994 13702 solver.cpp:414]     Test net output #1: loss = 0.00874085 (* 1 = 0.00874085 loss)
I0607 17:41:55.843401 13702 solver.cpp:242] Iteration 8800, loss = 0.00584094
I0607 17:41:55.843425 13702 solver.cpp:258]     Train net output #0: loss = 0.00553714 (* 1 = 0.00553714 loss)
I0607 17:41:55.843436 13702 solver.cpp:571] Iteration 8800, lr = 0.01
I0607 17:41:58.566161 13702 solver.cpp:346] Iteration 9000, Testing net (#0)
I0607 17:41:59.033143 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997012
I0607 17:41:59.033180 13702 solver.cpp:414]     Test net output #1: loss = 0.00751233 (* 1 = 0.00751233 loss)
I0607 17:41:59.037585 13702 solver.cpp:242] Iteration 9000, loss = 0.00571111
I0607 17:41:59.037605 13702 solver.cpp:258]     Train net output #0: loss = 0.00663349 (* 1 = 0.00663349 loss)
I0607 17:41:59.037616 13702 solver.cpp:571] Iteration 9000, lr = 0.01
I0607 17:42:01.761056 13702 solver.cpp:346] Iteration 9200, Testing net (#0)
I0607 17:42:02.226938 13702 solver.cpp:414]     Test net output #0: accuracy = 0.996667
I0607 17:42:02.226990 13702 solver.cpp:414]     Test net output #1: loss = 0.0084295 (* 1 = 0.0084295 loss)
I0607 17:42:02.231120 13702 solver.cpp:242] Iteration 9200, loss = 0.00526438
I0607 17:42:02.231142 13702 solver.cpp:258]     Train net output #0: loss = 0.00440009 (* 1 = 0.00440009 loss)
I0607 17:42:02.231153 13702 solver.cpp:571] Iteration 9200, lr = 0.01
I0607 17:42:04.956584 13702 solver.cpp:346] Iteration 9400, Testing net (#0)
I0607 17:42:05.418498 13702 solver.cpp:414]     Test net output #0: accuracy = 0.99675
I0607 17:42:05.418535 13702 solver.cpp:414]     Test net output #1: loss = 0.00870668 (* 1 = 0.00870668 loss)
I0607 17:42:05.422979 13702 solver.cpp:242] Iteration 9400, loss = 0.00541939
I0607 17:42:05.422999 13702 solver.cpp:258]     Train net output #0: loss = 0.00271814 (* 1 = 0.00271814 loss)
I0607 17:42:05.423010 13702 solver.cpp:571] Iteration 9400, lr = 0.01
I0607 17:42:08.139570 13702 solver.cpp:346] Iteration 9600, Testing net (#0)
I0607 17:42:08.604460 13702 solver.cpp:414]     Test net output #0: accuracy = 0.996748
I0607 17:42:08.604502 13702 solver.cpp:414]     Test net output #1: loss = 0.00827365 (* 1 = 0.00827365 loss)
I0607 17:42:08.608837 13702 solver.cpp:242] Iteration 9600, loss = 0.00611579
I0607 17:42:08.608856 13702 solver.cpp:258]     Train net output #0: loss = 0.00628194 (* 1 = 0.00628194 loss)
I0607 17:42:08.608883 13702 solver.cpp:571] Iteration 9600, lr = 0.01
I0607 17:42:11.325217 13702 solver.cpp:346] Iteration 9800, Testing net (#0)
I0607 17:42:11.788319 13702 solver.cpp:414]     Test net output #0: accuracy = 0.996748
I0607 17:42:11.788358 13702 solver.cpp:414]     Test net output #1: loss = 0.00890886 (* 1 = 0.00890886 loss)
I0607 17:42:11.792752 13702 solver.cpp:242] Iteration 9800, loss = 0.00526802
I0607 17:42:11.792771 13702 solver.cpp:258]     Train net output #0: loss = 0.00753762 (* 1 = 0.00753762 loss)
I0607 17:42:11.792783 13702 solver.cpp:571] Iteration 9800, lr = 0.01
I0607 17:42:14.508805 13702 solver.cpp:449] Snapshotting to binary proto file ./model_logs/fcn_iter_10000.caffemodel
I0607 17:42:14.604182 13702 solver.cpp:734] Snapshotting solver state to binary proto file./model_logs/fcn_iter_10000.solverstate
I0607 17:42:14.617346 13702 solver.cpp:346] Iteration 10000, Testing net (#0)
I0607 17:42:15.072116 13702 solver.cpp:414]     Test net output #0: accuracy = 0.996218
I0607 17:42:15.072159 13702 solver.cpp:414]     Test net output #1: loss = 0.0122453 (* 1 = 0.0122453 loss)
I0607 17:42:15.076267 13702 solver.cpp:242] Iteration 10000, loss = 0.00486753
I0607 17:42:15.076287 13702 solver.cpp:258]     Train net output #0: loss = 0.0062009 (* 1 = 0.0062009 loss)
I0607 17:42:15.076308 13702 solver.cpp:511] MultiStep Status: Iteration 10000, step = 1
I0607 17:42:15.076314 13702 solver.cpp:571] Iteration 10000, lr = 0.001
I0607 17:42:17.796423 13702 solver.cpp:346] Iteration 10200, Testing net (#0)
I0607 17:42:18.273114 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997158
I0607 17:42:18.273154 13702 solver.cpp:414]     Test net output #1: loss = 0.00742066 (* 1 = 0.00742066 loss)
I0607 17:42:18.277477 13702 solver.cpp:242] Iteration 10200, loss = 0.00518969
I0607 17:42:18.277496 13702 solver.cpp:258]     Train net output #0: loss = 0.00483834 (* 1 = 0.00483834 loss)
I0607 17:42:18.277506 13702 solver.cpp:571] Iteration 10200, lr = 0.001
I0607 17:42:21.002526 13702 solver.cpp:346] Iteration 10400, Testing net (#0)
I0607 17:42:21.482628 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997089
I0607 17:42:21.482671 13702 solver.cpp:414]     Test net output #1: loss = 0.00736595 (* 1 = 0.00736595 loss)
I0607 17:42:21.487071 13702 solver.cpp:242] Iteration 10400, loss = 0.00466267
I0607 17:42:21.487092 13702 solver.cpp:258]     Train net output #0: loss = 0.0117204 (* 1 = 0.0117204 loss)
I0607 17:42:21.487103 13702 solver.cpp:571] Iteration 10400, lr = 0.001
I0607 17:42:24.210523 13702 solver.cpp:346] Iteration 10600, Testing net (#0)
I0607 17:42:24.678344 13702 solver.cpp:414]     Test net output #0: accuracy = 0.9971
I0607 17:42:24.678383 13702 solver.cpp:414]     Test net output #1: loss = 0.00748381 (* 1 = 0.00748381 loss)
I0607 17:42:24.682783 13702 solver.cpp:242] Iteration 10600, loss = 0.00447222
I0607 17:42:24.682802 13702 solver.cpp:258]     Train net output #0: loss = 0.00585473 (* 1 = 0.00585473 loss)
I0607 17:42:24.682812 13702 solver.cpp:571] Iteration 10600, lr = 0.001
I0607 17:42:27.402719 13702 solver.cpp:346] Iteration 10800, Testing net (#0)
I0607 17:42:27.866484 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997202
I0607 17:42:27.866518 13702 solver.cpp:414]     Test net output #1: loss = 0.00728385 (* 1 = 0.00728385 loss)
I0607 17:42:27.870630 13702 solver.cpp:242] Iteration 10800, loss = 0.0044132
I0607 17:42:27.870649 13702 solver.cpp:258]     Train net output #0: loss = 0.00286127 (* 1 = 0.00286127 loss)
I0607 17:42:27.870661 13702 solver.cpp:571] Iteration 10800, lr = 0.001
I0607 17:42:30.591856 13702 solver.cpp:346] Iteration 11000, Testing net (#0)
I0607 17:42:31.056107 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997248
I0607 17:42:31.056143 13702 solver.cpp:414]     Test net output #1: loss = 0.00743893 (* 1 = 0.00743893 loss)
I0607 17:42:31.060266 13702 solver.cpp:242] Iteration 11000, loss = 0.00429411
I0607 17:42:31.060286 13702 solver.cpp:258]     Train net output #0: loss = 0.00679521 (* 1 = 0.00679521 loss)
I0607 17:42:31.060308 13702 solver.cpp:571] Iteration 11000, lr = 0.001
I0607 17:42:33.780292 13702 solver.cpp:346] Iteration 11200, Testing net (#0)
I0607 17:42:34.240640 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997295
I0607 17:42:34.240677 13702 solver.cpp:414]     Test net output #1: loss = 0.00728572 (* 1 = 0.00728572 loss)
I0607 17:42:34.245055 13702 solver.cpp:242] Iteration 11200, loss = 0.00429457
I0607 17:42:34.245074 13702 solver.cpp:258]     Train net output #0: loss = 0.00354418 (* 1 = 0.00354418 loss)
I0607 17:42:34.245085 13702 solver.cpp:571] Iteration 11200, lr = 0.001
I0607 17:42:36.960872 13702 solver.cpp:346] Iteration 11400, Testing net (#0)
I0607 17:42:37.423737 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997263
I0607 17:42:37.423776 13702 solver.cpp:414]     Test net output #1: loss = 0.00709753 (* 1 = 0.00709753 loss)
I0607 17:42:37.428148 13702 solver.cpp:242] Iteration 11400, loss = 0.00416084
I0607 17:42:37.428169 13702 solver.cpp:258]     Train net output #0: loss = 0.00416928 (* 1 = 0.00416928 loss)
I0607 17:42:37.428180 13702 solver.cpp:571] Iteration 11400, lr = 0.001
I0607 17:42:40.148005 13702 solver.cpp:346] Iteration 11600, Testing net (#0)
I0607 17:42:40.616395 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997299
I0607 17:42:40.616447 13702 solver.cpp:414]     Test net output #1: loss = 0.00696484 (* 1 = 0.00696484 loss)
I0607 17:42:40.620525 13702 solver.cpp:242] Iteration 11600, loss = 0.00421147
I0607 17:42:40.620545 13702 solver.cpp:258]     Train net output #0: loss = 0.00347182 (* 1 = 0.00347182 loss)
I0607 17:42:40.620566 13702 solver.cpp:571] Iteration 11600, lr = 0.001
I0607 17:42:43.341126 13702 solver.cpp:346] Iteration 11800, Testing net (#0)
I0607 17:42:43.809182 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997192
I0607 17:42:43.809221 13702 solver.cpp:414]     Test net output #1: loss = 0.00715548 (* 1 = 0.00715548 loss)
I0607 17:42:43.813633 13702 solver.cpp:242] Iteration 11800, loss = 0.0041997
I0607 17:42:43.813653 13702 solver.cpp:258]     Train net output #0: loss = 0.00441281 (* 1 = 0.00441281 loss)
I0607 17:42:43.813663 13702 solver.cpp:571] Iteration 11800, lr = 0.001
I0607 17:42:46.534451 13702 solver.cpp:346] Iteration 12000, Testing net (#0)
I0607 17:42:47.014855 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997171
I0607 17:42:47.014894 13702 solver.cpp:414]     Test net output #1: loss = 0.00730672 (* 1 = 0.00730672 loss)
I0607 17:42:47.019279 13702 solver.cpp:242] Iteration 12000, loss = 0.00416861
I0607 17:42:47.019297 13702 solver.cpp:258]     Train net output #0: loss = 0.00471935 (* 1 = 0.00471935 loss)
I0607 17:42:47.019307 13702 solver.cpp:571] Iteration 12000, lr = 0.001
I0607 17:42:49.740931 13702 solver.cpp:346] Iteration 12200, Testing net (#0)
I0607 17:42:50.212472 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997274
I0607 17:42:50.212512 13702 solver.cpp:414]     Test net output #1: loss = 0.00714243 (* 1 = 0.00714243 loss)
I0607 17:42:50.216588 13702 solver.cpp:242] Iteration 12200, loss = 0.0041522
I0607 17:42:50.216609 13702 solver.cpp:258]     Train net output #0: loss = 0.00706036 (* 1 = 0.00706036 loss)
I0607 17:42:50.216619 13702 solver.cpp:571] Iteration 12200, lr = 0.001
I0607 17:42:52.938416 13702 solver.cpp:346] Iteration 12400, Testing net (#0)
I0607 17:42:53.401929 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997297
I0607 17:42:53.401973 13702 solver.cpp:414]     Test net output #1: loss = 0.00729704 (* 1 = 0.00729704 loss)
I0607 17:42:53.406086 13702 solver.cpp:242] Iteration 12400, loss = 0.00400222
I0607 17:42:53.406106 13702 solver.cpp:258]     Train net output #0: loss = 0.00504143 (* 1 = 0.00504143 loss)
I0607 17:42:53.406117 13702 solver.cpp:571] Iteration 12400, lr = 0.001
I0607 17:42:54.760589 13702 solver.cpp:449] Snapshotting to binary proto file ./model_logs/fcn_iter_12500.caffemodel
I0607 17:42:54.791033 13702 solver.cpp:734] Snapshotting solver state to binary proto file./model_logs/fcn_iter_12500.solverstate
I0607 17:42:56.158247 13702 solver.cpp:346] Iteration 12600, Testing net (#0)
I0607 17:42:56.628556 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997344
I0607 17:42:56.628597 13702 solver.cpp:414]     Test net output #1: loss = 0.00718728 (* 1 = 0.00718728 loss)
I0607 17:42:56.632982 13702 solver.cpp:242] Iteration 12600, loss = 0.0040605
I0607 17:42:56.633002 13702 solver.cpp:258]     Train net output #0: loss = 0.00441849 (* 1 = 0.00441849 loss)
I0607 17:42:56.633011 13702 solver.cpp:571] Iteration 12600, lr = 0.001
I0607 17:42:59.357033 13702 solver.cpp:346] Iteration 12800, Testing net (#0)
I0607 17:42:59.821723 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997336
I0607 17:42:59.821769 13702 solver.cpp:414]     Test net output #1: loss = 0.00698928 (* 1 = 0.00698928 loss)
I0607 17:42:59.825860 13702 solver.cpp:242] Iteration 12800, loss = 0.00396549
I0607 17:42:59.825881 13702 solver.cpp:258]     Train net output #0: loss = 0.00310696 (* 1 = 0.00310696 loss)
I0607 17:42:59.825891 13702 solver.cpp:571] Iteration 12800, lr = 0.001
I0607 17:43:02.549235 13702 solver.cpp:346] Iteration 13000, Testing net (#0)
I0607 17:43:03.013093 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997324
I0607 17:43:03.013134 13702 solver.cpp:414]     Test net output #1: loss = 0.00694963 (* 1 = 0.00694963 loss)
I0607 17:43:03.017607 13702 solver.cpp:242] Iteration 13000, loss = 0.00404245
I0607 17:43:03.017628 13702 solver.cpp:258]     Train net output #0: loss = 0.00266115 (* 1 = 0.00266115 loss)
I0607 17:43:03.017638 13702 solver.cpp:571] Iteration 13000, lr = 0.001
I0607 17:43:05.739969 13702 solver.cpp:346] Iteration 13200, Testing net (#0)
I0607 17:43:06.207563 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997236
I0607 17:43:06.207602 13702 solver.cpp:414]     Test net output #1: loss = 0.00711364 (* 1 = 0.00711364 loss)
I0607 17:43:06.211987 13702 solver.cpp:242] Iteration 13200, loss = 0.0039772
I0607 17:43:06.212007 13702 solver.cpp:258]     Train net output #0: loss = 0.00334512 (* 1 = 0.00334512 loss)
I0607 17:43:06.212018 13702 solver.cpp:571] Iteration 13200, lr = 0.001
I0607 17:43:08.933660 13702 solver.cpp:346] Iteration 13400, Testing net (#0)
I0607 17:43:09.396803 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997227
I0607 17:43:09.396842 13702 solver.cpp:414]     Test net output #1: loss = 0.00724449 (* 1 = 0.00724449 loss)
I0607 17:43:09.401260 13702 solver.cpp:242] Iteration 13400, loss = 0.00398448
I0607 17:43:09.401280 13702 solver.cpp:258]     Train net output #0: loss = 0.00112393 (* 1 = 0.00112393 loss)
I0607 17:43:09.401290 13702 solver.cpp:571] Iteration 13400, lr = 0.001
I0607 17:43:12.126332 13702 solver.cpp:346] Iteration 13600, Testing net (#0)
I0607 17:43:12.594249 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997318
I0607 17:43:12.594302 13702 solver.cpp:414]     Test net output #1: loss = 0.00712667 (* 1 = 0.00712667 loss)
I0607 17:43:12.598413 13702 solver.cpp:242] Iteration 13600, loss = 0.00399659
I0607 17:43:12.598433 13702 solver.cpp:258]     Train net output #0: loss = 0.00412945 (* 1 = 0.00412945 loss)
I0607 17:43:12.598443 13702 solver.cpp:571] Iteration 13600, lr = 0.001
I0607 17:43:15.319310 13702 solver.cpp:346] Iteration 13800, Testing net (#0)
I0607 17:43:15.784422 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997363
I0607 17:43:15.784461 13702 solver.cpp:414]     Test net output #1: loss = 0.0071677 (* 1 = 0.0071677 loss)
I0607 17:43:15.788569 13702 solver.cpp:242] Iteration 13800, loss = 0.00387999
I0607 17:43:15.788589 13702 solver.cpp:258]     Train net output #0: loss = 0.00298849 (* 1 = 0.00298849 loss)
I0607 17:43:15.788599 13702 solver.cpp:571] Iteration 13800, lr = 0.001
I0607 17:43:18.501930 13702 solver.cpp:346] Iteration 14000, Testing net (#0)
I0607 17:43:18.969172 13702 solver.cpp:414]     Test net output #0: accuracy = 0.99737
I0607 17:43:18.969211 13702 solver.cpp:414]     Test net output #1: loss = 0.00712677 (* 1 = 0.00712677 loss)
I0607 17:43:18.973314 13702 solver.cpp:242] Iteration 14000, loss = 0.00387132
I0607 17:43:18.973335 13702 solver.cpp:258]     Train net output #0: loss = 0.0045946 (* 1 = 0.0045946 loss)
I0607 17:43:18.973345 13702 solver.cpp:571] Iteration 14000, lr = 0.001
I0607 17:43:21.695303 13702 solver.cpp:346] Iteration 14200, Testing net (#0)
I0607 17:43:22.170528 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997378
I0607 17:43:22.170562 13702 solver.cpp:414]     Test net output #1: loss = 0.0069249 (* 1 = 0.0069249 loss)
I0607 17:43:22.174973 13702 solver.cpp:242] Iteration 14200, loss = 0.00392059
I0607 17:43:22.174993 13702 solver.cpp:258]     Train net output #0: loss = 0.00294273 (* 1 = 0.00294273 loss)
I0607 17:43:22.175003 13702 solver.cpp:571] Iteration 14200, lr = 0.001
I0607 17:43:24.895434 13702 solver.cpp:346] Iteration 14400, Testing net (#0)
I0607 17:43:25.362115 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997351
I0607 17:43:25.362152 13702 solver.cpp:414]     Test net output #1: loss = 0.00687548 (* 1 = 0.00687548 loss)
I0607 17:43:25.366549 13702 solver.cpp:242] Iteration 14400, loss = 0.0038973
I0607 17:43:25.366570 13702 solver.cpp:258]     Train net output #0: loss = 0.00247595 (* 1 = 0.00247595 loss)
I0607 17:43:25.366581 13702 solver.cpp:571] Iteration 14400, lr = 0.001
I0607 17:43:28.085868 13702 solver.cpp:346] Iteration 14600, Testing net (#0)
I0607 17:43:28.556409 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997297
I0607 17:43:28.556449 13702 solver.cpp:414]     Test net output #1: loss = 0.00702553 (* 1 = 0.00702553 loss)
I0607 17:43:28.560818 13702 solver.cpp:242] Iteration 14600, loss = 0.00381208
I0607 17:43:28.560837 13702 solver.cpp:258]     Train net output #0: loss = 0.00379888 (* 1 = 0.00379888 loss)
I0607 17:43:28.560847 13702 solver.cpp:571] Iteration 14600, lr = 0.001
I0607 17:43:31.281265 13702 solver.cpp:346] Iteration 14800, Testing net (#0)
I0607 17:43:31.754477 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997294
I0607 17:43:31.754518 13702 solver.cpp:414]     Test net output #1: loss = 0.00715023 (* 1 = 0.00715023 loss)
I0607 17:43:31.758858 13702 solver.cpp:242] Iteration 14800, loss = 0.00383713
I0607 17:43:31.758878 13702 solver.cpp:258]     Train net output #0: loss = 0.00315823 (* 1 = 0.00315823 loss)
I0607 17:43:31.758889 13702 solver.cpp:571] Iteration 14800, lr = 0.001
I0607 17:43:34.476311 13702 solver.cpp:449] Snapshotting to binary proto file ./model_logs/fcn_iter_15000.caffemodel
I0607 17:43:34.507380 13702 solver.cpp:734] Snapshotting solver state to binary proto file./model_logs/fcn_iter_15000.solverstate
I0607 17:43:34.520768 13702 solver.cpp:326] Iteration 15000, loss = 0.00330521
I0607 17:43:34.520797 13702 solver.cpp:346] Iteration 15000, Testing net (#0)
I0607 17:43:34.973171 13702 solver.cpp:414]     Test net output #0: accuracy = 0.997344
I0607 17:43:34.973211 13702 solver.cpp:414]     Test net output #1: loss = 0.00707731 (* 1 = 0.00707731 loss)
I0607 17:43:34.973219 13702 solver.cpp:331] Optimization Done.
I0607 17:43:34.973225 13702 caffe.cpp:214] Optimization Done.
